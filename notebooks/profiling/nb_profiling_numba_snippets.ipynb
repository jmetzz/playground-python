{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numba demos snippets\n",
    "\n",
    "Numba is a compiler for Python array and numerical functions.\n",
    "\n",
    "## How does Numba work?\n",
    "Numba reads the Python bytecode for a decorated function and combines this with information about the types of the input arguments to the function. It analyzes and optimizes your code, and finally uses the LLVM compiler library to generate a machine code version of your function, tailored to your CPU capabilities. This compiled version is then used every time your function is called.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numba\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import config, jit, njit, threading_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(100).reshape(10, 10)\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def go_fast(a):  # Function is compiled and runs in machine code\n",
    "    trace = 0.0\n",
    "    for i in range(a.shape[0]):\n",
    "        trace += np.tanh(a[i, i])\n",
    "    return a + trace\n",
    "\n",
    "\n",
    "# DO NOT REPORT THIS... COMPILATION TIME IS INCLUDED IN THE EXECUTION TIME!\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (with compilation) = %s\" % (end - start))\n",
    "\n",
    "# NOW THE FUNCTION IS COMPILED, RE-TIME IT EXECUTING FROM CACHE\n",
    "start = time.time()\n",
    "go_fast(x)\n",
    "end = time.time()\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Even better time recording:\n",
    "# measure multiple iterations of execution and, as a result,\n",
    "# can be made to accommodate for the compilation time in the first execution.\n",
    "%timeit go_fast(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple example with pandas DataFrames\n",
    "\n",
    "\n",
    "def f(x):\n",
    "    return x * (x - 1)\n",
    "\n",
    "\n",
    "def integrate_f(a, b, N):\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "    for i in range(N):\n",
    "        s += f(a + i * dx)\n",
    "    return s * dx\n",
    "\n",
    "\n",
    "@jit\n",
    "def f_plain(x):\n",
    "    return x * (x - 1)\n",
    "\n",
    "\n",
    "@jit\n",
    "def integrate_f_numba(a, b, N):\n",
    "    s = 0\n",
    "    dx = (b - a) / N\n",
    "    for i in range(N):\n",
    "        s += f_plain(a + i * dx)\n",
    "    return s * dx\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def apply_integrate_f_numba(col_a, col_b, col_N):\n",
    "    n = len(col_N)\n",
    "    result = np.empty(n, dtype=np.float64)\n",
    "    assert len(col_a) == len(col_b) == n\n",
    "    for i in range(n):\n",
    "        result[i] = integrate_f_numba(col_a[i], col_b[i], col_N[i])\n",
    "    return result\n",
    "\n",
    "\n",
    "def compute_numba(df):\n",
    "    result = apply_integrate_f_numba(df[\"a\"].to_numpy(), df[\"b\"].to_numpy(), df[\"N\"].to_numpy())\n",
    "    return pd.Series(result, index=df.index, name=\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_df = pd.DataFrame(\n",
    "    {\"a\": np.random.randn(1000), \"b\": np.random.randn(1000), \"N\": np.random.randint(100, 1000, (1000)), \"x\": \"x\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit rand_df.apply(lambda x: integrate_f(x['a'], x['b'], x['N']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit compute_numba(rand_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel logistic regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True, parallel=True)\n",
    "def logistic_regression(Y, X, w, iterations):\n",
    "    for i in range(iterations):\n",
    "        w -= np.dot(((1.0 / (1.0 + np.exp(-Y * np.dot(X, w))) - 1.0) * Y), X)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the threading layer before any parallel target compilation\n",
    "config.THREADING_LAYER = \"threadsafe\"\n",
    "\n",
    "\n",
    "@njit(parallel=True)\n",
    "def foo(a, b):\n",
    "    return a + b\n",
    "\n",
    "\n",
    "x = np.arange(10.0)\n",
    "y = x.copy()\n",
    "\n",
    "# this will force the compilation of the function, select a threading layer\n",
    "# and then execute in parallel\n",
    "foo(x, y)\n",
    "\n",
    "# demonstrate the threading layer chosen\n",
    "print(\"Threading layer chosen: %s\" % threading_layer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
